#ë°ì´í„° ë¡œë“œ ë° ë¶„í• 

import pandas as pd

# ì—…ë¡œë“œí•œ pkl ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_pickle("/content/WM811K.pkl")

print(df.head())
print("train/val/test ë¶„í¬:", df["trainTestLabel"].value_counts())

#ë°ì´í„°ì…‹&ë°ì´í„°ë¡œë”

# ===== Colab ì „ìš©: WM-811K DataFrame ë²„ì „ â†’ Dataset/DataLoader í†µí•© ì…‹ì—… =====
# 1) GPU í™•ì¸
import torch, warnings, sys, subprocess
warnings.filterwarnings("ignore", category=DeprecationWarning)
print("CUDA available:", torch.cuda.is_available())

# 2) WM811K.pkl ì—…ë¡œë“œ (í•œ ë²ˆë§Œ ì—…ë¡œë“œí•˜ë©´ /content/ ì— ì¡´ì¬)
from google.colab import files
print("ğŸ‘‡ WM811K.pkl íŒŒì¼ì„ ì„ íƒí•´ì„œ ì—…ë¡œë“œí•˜ì„¸ìš”")
uploaded = files.upload()  # íŒŒì¼ ì„ íƒ ì°½ ëœ¸
PKL_PATH = "/content/WM811K.pkl"  # ì—…ë¡œë“œí•œ íŒŒì¼ëª…ì´ ë‹¤ë¥´ë©´ ì—¬ê¸°ë¥¼ ë°”ê¾¸ì„¸ìš”

# 3) ë¡œë“œ & ì •ê·œí™”(ë¼ë²¨/ìŠ¤í”Œë¦¿ì´ ë°°ì—´/ëŒ€ì†Œë¬¸ì ì„ì—¬ë„ ì•ˆì „)
df = pd.read_pickle(PKL_PATH)
print("DataFrame shape:", df.shape)
print("Columns:", df.columns.tolist())

def to_scalar_str(v):
    if isinstance(v, (list, tuple, np.ndarray)):
        a = np.array(v)
        if a.size == 1:
            try: v = a.item()
            except Exception: v = a.reshape(-1)[0]
        else:
            v = "|".join(map(str, a.reshape(-1).tolist()))
    return str(v)

# í•„ìˆ˜ ì»¬ëŸ¼ ì •ê·œí™”
assert "waferMap" in df.columns, "waferMap ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤."
assert "failureType" in df.columns, "failureType ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤."
df["failureType"] = df["failureType"].apply(to_scalar_str).str.strip()
if "trainTestLabel" in df.columns:
    df["trainTestLabel"] = df["trainTestLabel"].apply(to_scalar_str).str.strip()

# ì •ìƒ ë¼ë²¨ í‘œì¤€í™”
df["failureType"] = df["failureType"].replace(
    {"None":"none","NONE":"none","Null":"none","null":"none"}
)

# ìŠ¤í”Œë¦¿ í‘œì¤€í™” (training / test)
def normalize_split(v: str) -> str:
    lv = str(v).lower()
    if "train" in lv: return "training"
    if "test"  in lv: return "test"
    if lv in {"0","1"}: return "training" if lv=="0" else "test"
    return lv
if "trainTestLabel" in df.columns:
    df["trainTestLabel"] = df["trainTestLabel"].apply(normalize_split)

print("Unique failureType (sample 20):", sorted(df["failureType"].unique())[:20])
if "trainTestLabel" in df.columns:
    print("Split uniques:", sorted(df["trainTestLabel"].unique()))

# 4) ì œê³µ ìŠ¤í”Œë¦¿ ê·¸ëŒ€ë¡œ ì‚¬ìš© + trainâ†’val ë¶„í• 
SEED = 42
if "trainTestLabel" in df.columns:
    df_train_all = df[df["trainTestLabel"]=="training"].copy()
    df_test      = df[df["trainTestLabel"]=="test"].copy()
    if len(df_train_all)==0:
        raise RuntimeError("training í‘œê¸°ê°€ 0ê°œì…ë‹ˆë‹¤. ìœ„ ì¶œë ¥ì˜ Split uniquesë¥¼ í™•ì¸í•˜ê³  normalize_split ë¡œì§ì„ ì¡°ì •í•˜ì„¸ìš”.")
    df_train, df_val = train_test_split(
        df_train_all, test_size=0.15, random_state=SEED, stratify=df_train_all["failureType"]
    )
else:
    # ë§Œì•½ ìŠ¤í”Œë¦¿ì´ ì—†ìœ¼ë©´ 8:1:1ë¡œ ìƒì„±
    tr_all, df_test = train_test_split(df, test_size=0.1, random_state=SEED, stratify=df["failureType"])
    df_train, df_val = train_test_split(tr_all, test_size=0.111, random_state=SEED, stratify=tr_all["failureType"])  # 0.111*0.9 â‰ˆ 0.1

print(f"[SPLIT] train={len(df_train)}, val={len(df_val)}, test={len(df_test)}")

# 5) ë¼ë²¨ ë§¤í•‘
classes = sorted(df["failureType"].unique().tolist())
label2idx = {c:i for i,c in enumerate(classes)}
idx2label = {i:c for c,i in label2idx.items()}
print(f"#classes = {len(classes)}")

# 6) ì „ì²˜ë¦¬/ì¦ê°• ë³´ì¡° í•¨ìˆ˜
def to_tensor_1ch(img):
    """
    numpy/image-like â†’ torch.FloatTensor [1,H,W], ê°’ 0~1 ì •ê·œí™”
    """
    a = np.array(img)
    if a.ndim == 3 and a.shape[-1] == 1:
        a = a[...,0]
    a = a.astype(np.float32)
    # 0~1 ìŠ¤ì¼€ì¼
    amin, amax = float(a.min()), float(a.max())
    a = (a - amin) / (amax - amin + 1e-8) if amax > amin else np.zeros_like(a, dtype=np.float32)
    t = torch.from_numpy(a).float().unsqueeze(0)  # [1,H,W]
    return t

def resize_tensor_bilinear(t, size=128):
    return F.interpolate(t.unsqueeze(0), size=(size, size), mode="bilinear", align_corners=False).squeeze(0)

def random_geom_aug(t):
    # 90Â° íšŒì „ + ì¢Œìš°/ìƒí•˜ flip (ì›¨ì´í¼ ëŒ€ì¹­)
    k = random.choice([0,1,2,3])       # 0,90,180,270
    t = torch.rot90(t, k, dims=[1,2])
    if random.random() < 0.5:
        t = torch.flip(t, dims=[2])    # Hflip
    if random.random() < 0.5:
        t = torch.flip(t, dims=[1])    # Vflip
    return t

# 7) WaferDataset
from typing import Dict
class WaferDataset(Dataset):
    def __init__(self, df: pd.DataFrame, label2idx: Dict[str,int], train: bool = True, img_size: int = 128):
        self.df = df.reset_index(drop=True)
        self.label2idx = label2idx
        self.train = train
        self.img_size = img_size

    def __len__(self): return len(self.df)

    def __getitem__(self, i):
        row = self.df.iloc[i]
        img = row["waferMap"]
        y   = self.label2idx[str(row["failureType"])]
        t = to_tensor_1ch(img)
        t = resize_tensor_bilinear(t, self.img_size)
        if self.train:
            t = random_geom_aug(t)
        return t, y

# 8) DataLoader (+ë¶ˆê· í˜• ëŒ€ì‘ WeightedRandomSampler)
IMG_SIZE = 128
BATCH   = 128

train_ds = WaferDataset(df_train, label2idx, train=True,  img_size=IMG_SIZE)
val_ds   = WaferDataset(df_val,   label2idx, train=False, img_size=IMG_SIZE)
test_ds  = WaferDataset(df_test,  label2idx, train=False, img_size=IMG_SIZE)

# í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ (ë°˜ë¹„ë¡€ ê°€ì¤‘) + ìƒ˜í”ŒëŸ¬
vc = df_train["failureType"].value_counts()
w = np.array([1.0 / max(vc.get(lbl,1), 1) for lbl in classes], dtype=np.float32)
w = w / w.mean()
class_weight = torch.tensor(w, dtype=torch.float32)

sample_weights = df_train["failureType"].map(lambda s: class_weight[label2idx[s]].item()).values
sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)

train_loader = DataLoader(train_ds, batch_size=BATCH, sampler=sampler, num_workers=2, pin_memory=True)
val_loader   = DataLoader(val_ds,   batch_size=BATCH, shuffle=False,   num_workers=2, pin_memory=True)
test_loader  = DataLoader(test_ds,  batch_size=BATCH, shuffle=False,   num_workers=2, pin_memory=True)

print("[OK] DataLoaders ready.")

# 9) ë¹ ë¥¸ ë¬´ê²°ì„± ì²´í¬(í•œ ë°°ì¹˜ êº¼ë‚´ ë³´ê¸°)
imgs, labels = next(iter(train_loader))
print("Batch image tensor shape:", imgs.shape)   # (B,1,128,128)
print("Batch labels shape:", labels.shape)       # (B,)

# ë¼ë²¨ ì¼ë¶€ë¥¼ ì‹¤ì œ ì´ë¦„ìœ¼ë¡œ ë§¤í•‘í•´ë³´ê¸°
idx2label = {v:k for k,v in label2idx.items()}
print("Sample labels:", [idx2label[int(l)] for l in labels[:10]])

# 10) (ì„ íƒ) ë°°ì¹˜ ì‹œê°í™” 12ì¥
def show_grid(tensor_batch, label_batch, idx2label, cols=6):
    n = min(len(tensor_batch), cols*2)
    rows = math.ceil(n/cols)
    plt.figure(figsize=(cols*2, rows*2))
    for i in range(n):
        plt.subplot(rows, cols, i+1)
        plt.imshow(tensor_batch[i,0].cpu().numpy(), origin="lower", interpolation="nearest")
        plt.title(idx2label[int(label_batch[i])], fontsize=8)
        plt.xticks([]); plt.yticks([])
    plt.tight_layout(); plt.show()

show_grid(imgs, labels, idx2label, cols=6)

#CNN ëª¨ë¸ ì •ì˜

import torch
import torch.nn as nn
import torch.nn.functional as F

class WaferCNN(nn.Module):
    def __init__(self, num_classes, input_size=(1, 32, 32)):
        super(WaferCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)

        # ë™ì ìœ¼ë¡œ fc1 ì…ë ¥ ì°¨ì› ê³„ì‚°
        dummy_input = torch.zeros(1, *input_size)
        conv_output_size = self._get_conv_output_size(dummy_input)

        self.fc1 = nn.Linear(conv_output_size, 128)
        self.fc2 = nn.Linear(128, num_classes)

    def _get_conv_output_size(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        n_size = x.view(x.size(0), -1).size(1)
        return n_size

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(x.size(0), -1)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

        #í•™ìŠµ ë£¨í”„

import torch.optim as optim

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = WaferCNN(num_classes=len(label2idx)).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

for epoch in range(5):  # ì—í¬í¬ ìˆ˜ëŠ” ë‚˜ì¤‘ì— ì¡°ì ˆ
    model.train()
    running_loss = 0.0
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
    print(f"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}")

#í‰ê°€

from sklearn.metrics import classification_report

model.eval()
all_preds, all_labels = [], []

with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, preds = torch.max(outputs, 1)
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

print(classification_report(all_labels, all_preds, target_names=list(label2idx.keys())))
