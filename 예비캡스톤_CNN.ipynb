{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielkim717/3-2/blob/main/%EC%98%88%EB%B9%84%EC%BA%A1%EC%8A%A4%ED%86%A4_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy pandas matplotlib scikit-learn torch torchvision"
      ],
      "metadata": {
        "id": "DU3zFmniUbfY",
        "outputId": "2b8b6fa6-2f76-4706-efeb-719fa6a715d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # íŒŒì¼ ì„ íƒ â†’ WM811K.pkl ì—…ë¡œë“œ"
      ],
      "metadata": {
        "id": "DQWUcI_dUp4T",
        "outputId": "2c4d3cf1-cb2b-45bc-ba00-258a41178f23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 59
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-10fa3c08-763f-4130-8089-578bccda6353\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-10fa3c08-763f-4130-8089-578bccda6353\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ë°ì´í„° ë¡œë“œ ë° ë¶„í• \n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# ì—…ë¡œë“œí•œ pkl ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "df = pd.read_pickle(\"/content/WM811K.pkl\")\n",
        "\n",
        "print(df.head())\n",
        "print(\"train/val/test ë¶„í¬:\", df[\"trainTestLabel\"].value_counts())\n"
      ],
      "metadata": {
        "id": "Hi-GqvSIU3_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ë°ì´í„°ì…‹&ë°ì´í„°ë¡œë”\n",
        "\n",
        "# ===== Colab ì „ìš©: WM-811K DataFrame ë²„ì „ â†’ Dataset/DataLoader í†µí•© ì…‹ì—… =====\n",
        "# 1) í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "import sys\n",
        "import subprocess\n",
        "import random\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Dict\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "\n",
        "# 2) WM811K.pkl ì—…ë¡œë“œ (í•œ ë²ˆë§Œ ì—…ë¡œë“œí•˜ë©´ /content/ ì— ì¡´ì¬)\n",
        "from google.colab import files\n",
        "print(\"ğŸ‘‡ WM811K.pkl íŒŒì¼ì„ ì„ íƒí•´ì„œ ì—…ë¡œë“œí•˜ì„¸ìš”\")\n",
        "try:\n",
        "    uploaded = files.upload()\n",
        "    PKL_PATH = \"/content/WM811K.pkl\"\n",
        "except FileNotFoundError:\n",
        "    print(\"WM811K.pkl íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ê±°ë‚˜ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ì¡´ ê²½ë¡œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
        "    PKL_PATH = \"/content/WM811K.pkl\"\n",
        "except Exception as e:\n",
        "    print(f\"íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\")\n",
        "    sys.exit()\n",
        "\n",
        "# 3) ë¡œë“œ & ì •ê·œí™”(ë¼ë²¨/ìŠ¤í”Œë¦¿ì´ ë°°ì—´/ëŒ€ì†Œë¬¸ì ì„ì—¬ë„ ì•ˆì „)\n",
        "try:\n",
        "    df = pd.read_pickle(PKL_PATH)\n",
        "    print(\"DataFrame shape:\", df.shape)\n",
        "    print(\"Columns:\", df.columns.tolist())\n",
        "except Exception as e:\n",
        "    print(f\"íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\")\n",
        "    sys.exit()\n",
        "\n",
        "def to_scalar_str(v):\n",
        "    if isinstance(v, (list, tuple, np.ndarray)):\n",
        "        a = np.array(v)\n",
        "        if a.size == 1:\n",
        "            try: v = a.item()\n",
        "            except Exception: v = a.reshape(-1)[0]\n",
        "        else:\n",
        "            v = \"|\".join(map(str, a.reshape(-1).tolist()))\n",
        "    return str(v)\n",
        "\n",
        "# í•„ìˆ˜ ì»¬ëŸ¼ ì •ê·œí™”\n",
        "assert \"waferMap\" in df.columns, \"waferMap ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.\"\n",
        "assert \"failureType\" in df.columns, \"failureType ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.\"\n",
        "df[\"failureType\"] = df[\"failureType\"].apply(to_scalar_str).str.strip()\n",
        "if \"trainTestLabel\" in df.columns:\n",
        "    df[\"trainTestLabel\"] = df[\"trainTestLabel\"].apply(to_scalar_str).str.strip()\n",
        "\n",
        "# ì •ìƒ ë¼ë²¨ í‘œì¤€í™”\n",
        "df[\"failureType\"] = df[\"failureType\"].replace(\n",
        "    {\"None\":\"none\",\"NONE\":\"none\",\"Null\":\"none\",\"null\":\"none\"}\n",
        ")\n",
        "\n",
        "# ìŠ¤í”Œë¦¿ í‘œì¤€í™” (training / test)\n",
        "def normalize_split(v: str) -> str:\n",
        "    lv = str(v).lower()\n",
        "    if \"train\" in lv: return \"training\"\n",
        "    if \"test\"  in lv: return \"test\"\n",
        "    if lv in {\"0\",\"1\"}: return \"training\" if lv==\"0\" else \"test\"\n",
        "    return lv\n",
        "if \"trainTestLabel\" in df.columns:\n",
        "    df[\"trainTestLabel\"] = df[\"trainTestLabel\"].apply(normalize_split)\n",
        "\n",
        "print(\"Unique failureType (sample 20):\", sorted(df[\"failureType\"].unique())[:20])\n",
        "if \"trainTestLabel\" in df.columns:\n",
        "    print(\"Split uniques:\", sorted(df[\"trainTestLabel\"].unique()))\n",
        "\n",
        "# 4) ì œê³µ ìŠ¤í”Œë¦¿ ê·¸ëŒ€ë¡œ ì‚¬ìš© + trainâ†’val ë¶„í• \n",
        "SEED = 42\n",
        "if \"trainTestLabel\" in df.columns:\n",
        "    df_train_all = df[df[\"trainTestLabel\"]==\"training\"].copy()\n",
        "    df_test      = df[df[\"trainTestLabel\"]==\"test\"].copy()\n",
        "    if len(df_train_all)==0:\n",
        "        raise RuntimeError(\"training í‘œê¸°ê°€ 0ê°œì…ë‹ˆë‹¤. ìœ„ ì¶œë ¥ì˜ Split uniquesë¥¼ í™•ì¸í•˜ê³  normalize_split ë¡œì§ì„ ì¡°ì •í•˜ì„¸ìš”.\")\n",
        "    df_train, df_val = train_test_split(\n",
        "        df_train_all, test_size=0.15, random_state=SEED, stratify=df_train_all[\"failureType\"]\n",
        "    )\n",
        "else:\n",
        "    # ë§Œì•½ ìŠ¤í”Œë¦¿ì´ ì—†ìœ¼ë©´ 8:1:1ë¡œ ìƒì„±\n",
        "    tr_all, df_test = train_test_split(df, test_size=0.1, random_state=SEED, stratify=df[\"failureType\"])\n",
        "    df_train, df_val = train_test_split(tr_all, test_size=0.111, random_state=SEED, stratify=tr_all[\"failureType\"])  # 0.111*0.9 â‰ˆ 0.1\n",
        "\n",
        "print(f\"[SPLIT] train={len(df_train)}, val={len(df_val)}, test={len(df_test)}\")\n",
        "\n",
        "# 5) ë¼ë²¨ ë§¤í•‘\n",
        "classes = sorted(df[\"failureType\"].unique().tolist())\n",
        "label2idx = {c:i for i,c in enumerate(classes)}\n",
        "idx2label = {i:c for c,i in label2idx.items()}\n",
        "print(f\"#classes = {len(classes)}\")\n",
        "\n",
        "# 6) ì „ì²˜ë¦¬/ì¦ê°• ë³´ì¡° í•¨ìˆ˜\n",
        "def to_tensor_1ch(img):\n",
        "    \"\"\"\n",
        "    numpy/image-like â†’ torch.FloatTensor [1,H,W], ê°’ 0~1 ì •ê·œí™”\n",
        "    \"\"\"\n",
        "    a = np.array(img)\n",
        "    if a.ndim == 3 and a.shape[-1] == 1:\n",
        "        a = a[...,0]\n",
        "    a = a.astype(np.float32)\n",
        "    # 0~1 ìŠ¤ì¼€ì¼\n",
        "    amin, amax = float(a.min()), float(a.max())\n",
        "    a = (a - amin) / (amax - amin + 1e-8) if amax > amin else np.zeros_like(a, dtype=np.float32)\n",
        "    t = torch.from_numpy(a).float().unsqueeze(0)  # [1,H,W]\n",
        "    return t\n",
        "\n",
        "def resize_tensor_bilinear(t, size=128):\n",
        "    return F.interpolate(t.unsqueeze(0), size=(size, size), mode=\"bilinear\", align_corners=False).squeeze(0)\n",
        "\n",
        "def random_geom_aug(t):\n",
        "    # 90Â° íšŒì „ + ì¢Œìš°/ìƒí•˜ flip (ì›¨ì´í¼ ëŒ€ì¹­)\n",
        "    k = random.choice([0,1,2,3])\n",
        "    t = torch.rot90(t, k, dims=[1,2])\n",
        "    if random.random() < 0.5:\n",
        "        t = torch.flip(t, dims=[2])\n",
        "    if random.random() < 0.5:\n",
        "        t = torch.flip(t, dims=[1])\n",
        "    return t\n",
        "\n",
        "# 7) WaferDataset\n",
        "class WaferDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, label2idx: Dict[str,int], train: bool = True, img_size: int = 128):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.label2idx = label2idx\n",
        "        self.train = train\n",
        "        self.img_size = img_size\n",
        "\n",
        "    def __len__(self): return len(self.df)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        row = self.df.iloc[i]\n",
        "        img = row[\"waferMap\"]\n",
        "        y   = self.label2idx[str(row[\"failureType\"])]\n",
        "        t = to_tensor_1ch(img)\n",
        "        t = resize_tensor_bilinear(t, self.img_size)\n",
        "        if self.train:\n",
        "            t = random_geom_aug(t)\n",
        "        return t, y\n",
        "\n",
        "# 8) DataLoader (+ë¶ˆê· í˜• ëŒ€ì‘ WeightedRandomSampler)\n",
        "IMG_SIZE = 128\n",
        "BATCH  = 128\n",
        "\n",
        "train_ds = WaferDataset(df_train, label2idx, train=True,  img_size=IMG_SIZE)\n",
        "val_ds   = WaferDataset(df_val,   label2idx, train=False, img_size=IMG_SIZE)\n",
        "test_ds  = WaferDataset(df_test,  label2idx, train=False, img_size=IMG_SIZE)\n",
        "\n",
        "# í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ (ë°˜ë¹„ë¡€ ê°€ì¤‘) + ìƒ˜í”ŒëŸ¬\n",
        "vc = df_train[\"failureType\"].value_counts()\n",
        "w = np.array([1.0 / max(vc.get(lbl,1), 1) for lbl in classes], dtype=np.float32)\n",
        "w = w / w.mean()\n",
        "class_weight = torch.tensor(w, dtype=torch.float32)\n",
        "\n",
        "sample_weights = df_train[\"failureType\"].map(lambda s: class_weight[label2idx[s]].item()).values\n",
        "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH, sampler=sampler, num_workers=2, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH, shuffle=False,   num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH, shuffle=False,   num_workers=2, pin_memory=True)\n",
        "\n",
        "print(\"[OK] DataLoaders ready.\")\n",
        "\n",
        "# 9) ë¹ ë¥¸ ë¬´ê²°ì„± ì²´í¬(í•œ ë°°ì¹˜ êº¼ë‚´ ë³´ê¸°)\n",
        "imgs, labels = next(iter(train_loader))\n",
        "print(\"Batch image tensor shape:\", imgs.shape)\n",
        "print(\"Batch labels shape:\", labels.shape)\n",
        "\n",
        "# ë¼ë²¨ ì¼ë¶€ë¥¼ ì‹¤ì œ ì´ë¦„ìœ¼ë¡œ ë§¤í•‘í•´ë³´ê¸°\n",
        "idx2label = {v:k for k,v in label2idx.items()}\n",
        "print(\"Sample labels:\", [idx2label[int(l)] for l in labels[:10]])\n",
        "\n",
        "# 10) (ì„ íƒ) ë°°ì¹˜ ì‹œê°í™” 12ì¥\n",
        "def show_grid(tensor_batch, label_batch, idx2label, cols=6):\n",
        "    n = min(len(tensor_batch), cols*2)\n",
        "    rows = math.ceil(n/cols)\n",
        "    plt.figure(figsize=(cols*2, rows*2))\n",
        "    for i in range(n):\n",
        "        plt.subplot(rows, cols, i+1)\n",
        "        plt.imshow(tensor_batch[i,0].cpu().numpy(), origin=\"lower\", interpolation=\"nearest\")\n",
        "        plt.title(idx2label[int(label_batch[i])], fontsize=8)\n",
        "        plt.xticks([]); plt.yticks([])\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "show_grid(imgs, labels, idx2label, cols=6)"
      ],
      "metadata": {
        "id": "EcKFu57hVUyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class WaferCNN(nn.Module):\n",
        "    def __init__(self, num_classes, input_size=(1, 128, 128)):\n",
        "        super(WaferCNN, self).__init__()\n",
        "\n",
        "        # ì²« ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë¸”ë¡ (Conv -> ReLU -> BatchNorm -> Pool)\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(32), # ë°°ì¹˜ ì •ê·œí™” ì¶”ê°€\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # ë‘ ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë¸”ë¡\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(64), # ë°°ì¹˜ ì •ê·œí™” ì¶”ê°€\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "\n",
        "        # ë™ì ìœ¼ë¡œ fc1 ì…ë ¥ ì°¨ì› ê³„ì‚°\n",
        "        dummy_input = torch.zeros(1, *input_size)\n",
        "        conv_output_size = self._get_conv_output_size(dummy_input)\n",
        "\n",
        "        # ë¶„ë¥˜ê¸° (Classifier)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(conv_output_size, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5), # ë“œë¡­ì•„ì›ƒ ì¶”ê°€ (ì¼ë°˜ì ìœ¼ë¡œ 0.5ë¥¼ ë§ì´ ì‚¬ìš©)\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def _get_conv_output_size(self, x):\n",
        "        \"\"\"\n",
        "        ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°ì— ë”°ë¼ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ ì¶œë ¥ í¬ê¸°ë¥¼ ë™ì ìœ¼ë¡œ ê³„ì‚°í•˜ëŠ” í—¬í¼ í•¨ìˆ˜\n",
        "        \"\"\"\n",
        "        with torch.no_grad(): # ê³„ì‚° ê·¸ë˜í”„ë¥¼ ë§Œë“¤ í•„ìš”ê°€ ì—†ìœ¼ë¯€ë¡œ íš¨ìœ¨ì \n",
        "            x = self.features(x)\n",
        "            n_size = x.view(x.size(0), -1).size(1)\n",
        "        return n_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "mFcvBo_ZU9O1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# ===== 1. ì„¤ì • ë° ì´ˆê¸°í™” =====\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ëª¨ë¸, ì†ì‹¤ í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™”\n",
        "model = WaferCNN(num_classes=len(label2idx)).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ (ê²€ì¦ ì†ì‹¤ì´ ê°œì„ ë˜ì§€ ì•Šì„ ë•Œ í•™ìŠµë¥  ê°ì†Œ)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
        "\n",
        "# ìµœì  ëª¨ë¸ ì €ì¥ì„ ìœ„í•œ ë³€ìˆ˜ ì´ˆê¸°í™”\n",
        "best_val_loss = float('inf')\n",
        "num_epochs = 10 # ì—í¬í¬ ìˆ˜ë¥¼ 10ìœ¼ë¡œ ì„¤ì • (ì¡°ì ˆ ê°€ëŠ¥)\n",
        "\n",
        "# ===== 2. í•™ìŠµ ë° ê²€ì¦ ë£¨í”„ =====\n",
        "for epoch in range(num_epochs):\n",
        "    # í›ˆë ¨ ë‹¨ê³„\n",
        "    model.train() # ëª¨ë¸ì„ í›ˆë ¨ ëª¨ë“œë¡œ ì„¤ì •\n",
        "    train_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "\n",
        "    # ê²€ì¦ ë‹¨ê³„\n",
        "    model.eval() # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad(): # ê²€ì¦ ë‹¨ê³„ì—ì„œëŠ” ê¸°ìš¸ê¸° ê³„ì‚° ë¹„í™œì„±í™”\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    val_accuracy = 100 * correct / total\n",
        "\n",
        "    # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # ê²°ê³¼ ì¶œë ¥\n",
        "    print(f'Epoch {epoch+1}/{num_epochs} | '\n",
        "          f'Train Loss: {train_loss:.4f} | '\n",
        "          f'Val Loss: {val_loss:.4f} | '\n",
        "          f'Val Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "    # ìµœì  ëª¨ë¸ ì €ì¥\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), 'best_wafer_model.pth')\n",
        "        print(f'-> Model saved! Best validation loss: {best_val_loss:.4f}')\n",
        "\n",
        "print(\"Training finished.\")"
      ],
      "metadata": {
        "id": "Mum3scJxVLnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n",
        "model.eval()\n",
        "\n",
        "# ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œ ë¼ë²¨ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
        "all_preds, all_labels = [], []\n",
        "\n",
        "# ì¶”ë¡  ì‹œ ê¸°ìš¸ê¸° ê³„ì‚° ë¹„í™œì„±í™” (ë©”ëª¨ë¦¬ ì ˆì•½ ë° ì†ë„ í–¥ìƒ)\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        # ì˜ˆì¸¡ê°’ê³¼ ë¼ë²¨ì„ CPUë¡œ ì´ë™ í›„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# ë¶„ë¥˜ ë¦¬í¬íŠ¸ ì¶œë ¥\n",
        "print(\"ë¶„ë¥˜ ë¦¬í¬íŠ¸:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=list(label2idx.keys())))\n",
        "\n",
        "# í˜¼ë™ í–‰ë ¬ ìƒì„± ë° ì‹œê°í™”\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=list(label2idx.keys()), yticklabels=list(label2idx.keys()))\n",
        "plt.title('í˜¼ë™ í–‰ë ¬ (Confusion Matrix)')\n",
        "plt.xlabel('ì˜ˆì¸¡ ë¼ë²¨ (Predicted Label)')\n",
        "plt.ylabel('ì‹¤ì œ ë¼ë²¨ (True Label)')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sG5FE79NVOpr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}